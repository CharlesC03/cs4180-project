{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from agent import DQN, ExponentialSchedule, train_dqn\n",
    "from env import PokerEnvironment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, *, window_size=50):\n",
    "    \"\"\"Smooths 1-D data array using a moving average.\n",
    "\n",
    "    Args:\n",
    "        data: 1-D numpy.array\n",
    "        window_size: Size of the smoothing window\n",
    "\n",
    "    Returns:\n",
    "        smooth_data: A 1-d numpy.array with the same size as data\n",
    "    \"\"\"\n",
    "    assert data.ndim == 1\n",
    "    if len(data) < window_size:\n",
    "        return data\n",
    "    kernel = np.ones(window_size)\n",
    "    smooth_data = np.convolve(data, kernel) / np.convolve(np.ones_like(data), kernel)\n",
    "    return smooth_data[: -window_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (180553888.py, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 38\u001b[0;36m\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    env = PokerEnvironment()\n",
    "    gamma = 0.99\n",
    "\n",
    "    # We train for many time-steps; as usual, you can decrease this during development / debugging,\n",
    "    # but make sure to restore it to 1_500_000 before submitting\n",
    "    num_steps = 1_500_000\n",
    "    num_saves = 5  # Save models at 0%, 25%, 50%, 75% and 100% of training\n",
    "\n",
    "    replay_size = 200_000\n",
    "    replay_prepopulate_steps = 50_000\n",
    "\n",
    "    batch_size = 64\n",
    "    exploration = ExponentialSchedule(1.0, 0.05, 1_000_000)\n",
    "\n",
    "    model_class = DQN\n",
    "\n",
    "    # This should take about 1-2 hours on a generic 4-core laptop\n",
    "    dqn_models, returns, lengths, losses = train_dqn(\n",
    "        env,\n",
    "        num_steps,\n",
    "        num_saves=num_saves,\n",
    "        model=model_class,\n",
    "        replay_size=replay_size,\n",
    "        replay_prepopulate_steps=replay_prepopulate_steps,\n",
    "        batch_size=batch_size,\n",
    "        exploration=exploration,\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "    assert len(dqn_models) == num_saves\n",
    "    assert all(isinstance(value, model_class) for value in dqn_models.values())\n",
    "\n",
    "    # Saving computed models to disk, so that we can load and visualize them later\n",
    "    checkpoint = {key: dqn.custom_dump() for key, dqn in dqn_models.items()}\n",
    "    torch.save(checkpoint, f\"models/checkpoint_poker_{num_steps}.pt\")\n",
    "    np.savez(f\"data_backups/{num_steps}_data.npz\", arr1=returns, arr2=lengths, arr3=losses)\n",
    "    \n",
    "    # YOUR PLOTTING CODE HERE\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "    for player_returns in returns:\n",
    "        axs[0].plot(moving_average(player_returns, window_size=50))\n",
    "    axs[0].set_xlabel(\"Episode\")\n",
    "    axs[0].set_ylabel(\"Returns\")\n",
    "\n",
    "    axs[1].plot(moving_average(lengths, window_size=50))\n",
    "    axs[1].set_xlabel(\"Episode\")\n",
    "    axs[1].set_ylabel(\"Lengths\")\n",
    "\n",
    "    axs[2].plot(moving_average(losses, window_size=50))\n",
    "    axs[2].set_xlabel(\"Episode\")\n",
    "    axs[2].set_ylabel(\"Losses\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"graphs/poker_training{num_steps}.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"FAILED: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    env = PokerEnvironment()\n",
    "    gamma = 0.99\n",
    "\n",
    "    # We train for many time-steps; as usual, you can decrease this during development / debugging,\n",
    "    # but make sure to restore it to 1_500_000 before submitting\n",
    "    num_steps = 100_000\n",
    "    num_saves = 5  # Save models at 0%, 25%, 50%, 75% and 100% of training\n",
    "\n",
    "    replay_size = 5_000_000\n",
    "    replay_prepopulate_steps = 50_000\n",
    "\n",
    "    batch_size = 64\n",
    "    exploration = ExponentialSchedule(1.0, 0.05, 2_000_000)\n",
    "\n",
    "    model_class = DQN\n",
    "\n",
    "    # This should take about 1-2 hours on a generic 4-core laptop\n",
    "    dqn_models, returns, lengths, losses = train_dqn(\n",
    "        env,\n",
    "        num_steps,\n",
    "        num_saves=num_saves,\n",
    "        model=model_class,\n",
    "        model_num_layers=32,\n",
    "        model_hidden_dim=1024,\n",
    "        replay_size=replay_size,\n",
    "        replay_prepopulate_steps=replay_prepopulate_steps,\n",
    "        batch_size=batch_size,\n",
    "        exploration=exploration,\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "    assert len(dqn_models) == num_saves\n",
    "    assert all(isinstance(value, model_class) for value in dqn_models.values())\n",
    "\n",
    "    # Saving computed models to disk, so that we can load and visualize them later\n",
    "    checkpoint = {key: dqn.custom_dump() for key, dqn in dqn_models.items()}\n",
    "    torch.save(checkpoint, f\"models/checkpoint_poker_32x1024_{num_steps}.pt\")\n",
    "    np.savez(\n",
    "        f\"data_backups/32x1024_{num_steps}_data.npz\",\n",
    "        arr1=returns,\n",
    "        arr2=lengths,\n",
    "        arr3=losses,\n",
    "    )\n",
    "\n",
    "    # YOUR PLOTTING CODE HERE\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "    for player_returns in returns:\n",
    "        axs[0].plot(moving_average(player_returns, window_size=50))\n",
    "    axs[0].set_xlabel(\"Episode\")\n",
    "    axs[0].set_ylabel(\"Returns\")\n",
    "\n",
    "    axs[1].plot(moving_average(lengths, window_size=50))\n",
    "    axs[1].set_xlabel(\"Episode\")\n",
    "    axs[1].set_ylabel(\"Lengths\")\n",
    "\n",
    "    axs[2].plot(moving_average(losses, window_size=50))\n",
    "    axs[2].set_xlabel(\"Episode\")\n",
    "    axs[2].set_ylabel(\"Losses\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"graphs/poker_training_32x1024_{num_steps}.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    env = PokerEnvironment()\n",
    "    gamma = 0.99\n",
    "\n",
    "    # We train for many time-steps; as usual, you can decrease this during development / debugging,\n",
    "    # but make sure to restore it to 1_500_000 before submitting\n",
    "    num_steps = 100_000\n",
    "    num_saves = 5  # Save models at 0%, 25%, 50%, 75% and 100% of training\n",
    "\n",
    "    replay_size = 3_000_000\n",
    "    replay_prepopulate_steps = 50_000\n",
    "\n",
    "    batch_size = 64\n",
    "    exploration = ExponentialSchedule(1.0, 0.05, 1_000_000)\n",
    "\n",
    "    model_class = DQN\n",
    "\n",
    "    # This should take about 1-2 hours on a generic 4-core laptop\n",
    "    dqn_models, returns, lengths, losses = train_dqn(\n",
    "        env,\n",
    "        num_steps,\n",
    "        num_saves=num_saves,\n",
    "        model=model_class,\n",
    "        model_num_layers=8,\n",
    "        model_hidden_dim=256,\n",
    "        replay_size=replay_size,\n",
    "        replay_prepopulate_steps=replay_prepopulate_steps,\n",
    "        batch_size=batch_size,\n",
    "        exploration=exploration,\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "    assert len(dqn_models) == num_saves\n",
    "    assert all(isinstance(value, model_class) for value in dqn_models.values())\n",
    "\n",
    "    # Saving computed models to disk, so that we can load and visualize them later\n",
    "    checkpoint = {key: dqn.custom_dump() for key, dqn in dqn_models.items()}\n",
    "    torch.save(checkpoint, f\"models/checkpoint_poker_8x256_{num_steps}.pt\")\n",
    "    np.savez(\n",
    "        f\"data_backups/8x256_{num_steps}_data.npz\",\n",
    "        arr1=returns,\n",
    "        arr2=lengths,\n",
    "        arr3=losses,\n",
    "    )\n",
    "    # YOUR PLOTTING CODE HERE\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "    for player_returns in returns:\n",
    "        axs[0].plot(moving_average(player_returns, window_size=50))\n",
    "    axs[0].set_xlabel(\"Episode\")\n",
    "    axs[0].set_ylabel(\"Returns\")\n",
    "\n",
    "    axs[1].plot(moving_average(lengths, window_size=50))\n",
    "    axs[1].set_xlabel(\"Episode\")\n",
    "    axs[1].set_ylabel(\"Lengths\")\n",
    "\n",
    "    axs[2].plot(moving_average(losses, window_size=50))\n",
    "    axs[2].set_xlabel(\"Episode\")\n",
    "    axs[2].set_ylabel(\"Losses\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"graphs/poker_training_8x256_{num_steps}.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    env = PokerEnvironment()\n",
    "    gamma = 1\n",
    "\n",
    "    # We train for many time-steps; as usual, you can decrease this during development / debugging,\n",
    "    # but make sure to restore it to 1_500_000 before submitting\n",
    "    num_steps = 100_000\n",
    "    num_saves = 5  # Save models at 0%, 25%, 50%, 75% and 100% of training\n",
    "\n",
    "    replay_size = 2_000_000\n",
    "    replay_prepopulate_steps = 50_000\n",
    "\n",
    "    batch_size = 64\n",
    "    exploration = ExponentialSchedule(1.0, 0.05, 1_000_000)\n",
    "\n",
    "    model_class = DQN\n",
    "\n",
    "    # This should take about 1-2 hours on a generic 4-core laptop\n",
    "    dqn_models, returns, lengths, losses = train_dqn(\n",
    "        env,\n",
    "        num_steps,\n",
    "        num_saves=num_saves,\n",
    "        model=model_class,\n",
    "        model_num_layers=8,\n",
    "        model_hidden_dim=256,\n",
    "        replay_size=replay_size,\n",
    "        replay_prepopulate_steps=replay_prepopulate_steps,\n",
    "        batch_size=batch_size,\n",
    "        exploration=exploration,\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "    assert len(dqn_models) == num_saves\n",
    "    assert all(isinstance(value, model_class) for value in dqn_models.values())\n",
    "\n",
    "    # Saving computed models to disk, so that we can load and visualize them later\n",
    "    checkpoint = {key: dqn.custom_dump() for key, dqn in dqn_models.items()}\n",
    "    torch.save(checkpoint, f\"models/checkpoint_poker_8x256_gamma1_{num_steps}.pt\")\n",
    "    np.savez(\n",
    "        f\"data_backups/8x256_gamma1_{num_steps}_data.npz\",\n",
    "        arr1=returns,\n",
    "        arr2=lengths,\n",
    "        arr3=losses,\n",
    "    )\n",
    "    # YOUR PLOTTING CODE HERE\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "    for player_returns in returns:\n",
    "        axs[0].plot(moving_average(player_returns, window_size=50))\n",
    "    axs[0].set_xlabel(\"Episode\")\n",
    "    axs[0].set_ylabel(\"Returns\")\n",
    "\n",
    "    axs[1].plot(moving_average(lengths, window_size=50))\n",
    "    axs[1].set_xlabel(\"Episode\")\n",
    "    axs[1].set_ylabel(\"Lengths\")\n",
    "\n",
    "    axs[2].plot(moving_average(losses, window_size=50))\n",
    "    axs[2].set_xlabel(\"Episode\")\n",
    "    axs[2].set_ylabel(\"Losses\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"graphs/poker_training_8x256_gamma1_{num_steps}.png\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"FAILED: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PokerEnvironment()\n",
    "gamma = 0.99\n",
    "\n",
    "# We train for many time-steps; as usual, you can decrease this during development / debugging,\n",
    "# but make sure to restore it to 1_500_000 before submitting\n",
    "num_steps = 100_000\n",
    "num_saves = 5  # Save models at 0%, 25%, 50%, 75% and 100% of training\n",
    "\n",
    "replay_size = 5_000_000\n",
    "replay_prepopulate_steps = 50_000\n",
    "\n",
    "batch_size = 64\n",
    "exploration = ExponentialSchedule(1.0, 0.05, 2_000_000)\n",
    "\n",
    "model_class = DQN\n",
    "\n",
    "# This should take about 1-2 hours on a generic 4-core laptop\n",
    "dqn_models, returns, lengths, losses = train_dqn(\n",
    "    env,\n",
    "    num_steps,\n",
    "    num_saves=num_saves,\n",
    "    model=model_class,\n",
    "    model_num_layers=50,\n",
    "    model_hidden_dim=1024,\n",
    "    replay_size=replay_size,\n",
    "    replay_prepopulate_steps=replay_prepopulate_steps,\n",
    "    batch_size=batch_size,\n",
    "    exploration=exploration,\n",
    "    gamma=gamma,\n",
    ")\n",
    "\n",
    "assert len(dqn_models) == num_saves\n",
    "assert all(isinstance(value, model_class) for value in dqn_models.values())\n",
    "\n",
    "# Saving computed models to disk, so that we can load and visualize them later\n",
    "checkpoint = {key: dqn.custom_dump() for key, dqn in dqn_models.items()}\n",
    "torch.save(checkpoint, f\"models/checkpoint_poker_50x1024_{num_steps}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poker-agent-UTPq6ugP-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
